{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dpcATxjK4ffi",
        "outputId": "2a489ae6-5de8-4ee8-a403-321e0194f13c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in c:\\users\\dodam\\anaconda3\\lib\\site-packages (0.28.1)\n",
            "Requirement already satisfied: ultralytics in c:\\users\\dodam\\anaconda3\\lib\\site-packages (8.3.68)\n",
            "Requirement already satisfied: filelock in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (2.5.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (6.1.1)\n",
            "Requirement already satisfied: py-cpuinfo in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2024.12.14)\n",
            "Requirement already satisfied: networkx in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: doclayout-yolo in c:\\users\\dodam\\anaconda3\\lib\\site-packages (0.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (3.9.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (1.13.1)\n",
            "Requirement already satisfied: torch>=2.0.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (2.5.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.15.2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (0.20.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (4.66.5)\n",
            "Requirement already satisfied: psutil in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from doclayout-yolo) (6.1.1)\n",
            "Requirement already satisfied: py-cpuinfo in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (0.13.2)\n",
            "Requirement already satisfied: albumentations>=1.4.11 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from doclayout-yolo) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from albumentations>=1.4.11->doclayout-yolo) (1.26.4)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from albumentations>=1.4.11->doclayout-yolo) (2.10.6)\n",
            "Requirement already satisfied: albucore==0.0.23 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from albumentations>=1.4.11->doclayout-yolo) (0.0.23)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from albumentations>=1.4.11->doclayout-yolo) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from albucore==0.0.23->albumentations>=1.4.11->doclayout-yolo) (3.11.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from albucore==0.0.23->albumentations>=1.4.11->doclayout-yolo) (6.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->doclayout-yolo) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->doclayout-yolo) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->doclayout-yolo) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->doclayout-yolo) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->doclayout-yolo) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->doclayout-yolo) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->doclayout-yolo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->doclayout-yolo) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->doclayout-yolo) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests>=2.23.0->doclayout-yolo) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests>=2.23.0->doclayout-yolo) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests>=2.23.0->doclayout-yolo) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests>=2.23.0->doclayout-yolo) (2024.12.14)\n",
            "Requirement already satisfied: filelock in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=2.0.1->doclayout-yolo) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=2.0.1->doclayout-yolo) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=2.0.1->doclayout-yolo) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=2.0.1->doclayout-yolo) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=2.0.1->doclayout-yolo) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=2.0.1->doclayout-yolo) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch>=2.0.1->doclayout-yolo) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.1->doclayout-yolo) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.64.0->doclayout-yolo) (0.4.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->doclayout-yolo) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.1->doclayout-yolo) (2.1.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'DocLayout-YOLO' already exists and is not an empty directory.\n",
            "'apt-get'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n",
            "'apt-get'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\dodam\\anaconda3\\lib\\site-packages (2.5.1+cu118)\n",
            "Collecting transformers==4.40.0\n",
            "  Using cached transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
            "Requirement already satisfied: accelerate in c:\\users\\dodam\\anaconda3\\lib\\site-packages (1.3.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers==4.40.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers==4.40.0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers==4.40.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.40.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers==4.40.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers==4.40.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers==4.40.0) (2.32.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.0)\n",
            "  Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers==4.40.0) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers==4.40.0) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (6.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers==4.40.0) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->transformers==4.40.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->transformers==4.40.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->transformers==4.40.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->transformers==4.40.0) (2024.12.14)\n",
            "Using cached transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
            "Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.2\n",
            "    Uninstalling transformers-4.48.2:\n",
            "      Successfully uninstalled transformers-4.48.2\n",
            "Successfully installed tokenizers-0.19.1 transformers-4.40.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
            "    #\n",
            "    ^\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\dodam\\anaconda3\\lib\\site-packages (4.40.0)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: tokenizers in c:\\users\\dodam\\anaconda3\\lib\\site-packages (0.19.1)\n",
            "Collecting tokenizers\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\dodam\\anaconda3\\lib\\site-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\dodam\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dodam\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
            "Using cached transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
            "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.0\n",
            "    Uninstalling transformers-4.40.0:\n",
            "      Successfully uninstalled transformers-4.40.0\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.48.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
            "    #\n",
            "    ^\n"
          ]
        }
      ],
      "source": [
        "# 0) 환경 세팅 및 라이브러리 설치\n",
        "\n",
        "# Hugging Face 라이브러리 설치\n",
        "!pip install huggingface_hub ultralytics\n",
        "!pip install doclayout-yolo\n",
        "!git clone https://github.com/opendatalab/DocLayout-YOLO.git\n",
        "\n",
        "# 필요한 시스템 패키지 및 라이브러리 설치\n",
        "!apt-get update\n",
        "!apt-get install -y poppler-utils  # PDF → 이미지 변환에 필요한 poppler\n",
        "!pip install torch transformers==4.40.0 accelerate\n",
        "!pip install pdf2image            # PDF → 이미지 변환 라이브러리\n",
        "!pip install --upgrade transformers tokenizers huggingface_hub\n",
        "!pip install easyocr              # OCR을 위한 easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfF5ydO77ilc",
        "outputId": "7ecf1604-26d9-4b78-a2df-071308d5145e"
      },
      "outputs": [],
      "source": [
        "# 1) 필요한 Python 라이브러리 임포트\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import json\n",
        "from doclayout_yolo import YOLOv10  # DocLayout-YOLO\n",
        "import os\n",
        "import uuid\n",
        "from pdf2image import convert_from_path\n",
        "import easyocr\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import transformers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NjU1iwuk8Ahq"
      },
      "outputs": [],
      "source": [
        "# 2) PDF → 이미지 변환 함수 정의\n",
        "\n",
        "def pdf_to_jpg(pdf_path, output_folder=\"images\", dpi=300):\n",
        "    \"\"\"\n",
        "    PDF 파일을 지정된 DPI로 페이지별 JPG 이미지로 변환하고,\n",
        "    변환된 이미지 경로 리스트를 반환한다.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # PDF를 이미지로 변환\n",
        "    images = convert_from_path(pdf_path, dpi=dpi)\n",
        "\n",
        "    image_paths = []\n",
        "    for i, image in enumerate(images):\n",
        "        image_path = os.path.join(output_folder, f\"page_{i+1}.jpg\")\n",
        "        image.save(image_path, \"JPEG\")\n",
        "        image_paths.append(image_path)\n",
        "\n",
        "    print(f\"Converted PDF to {len(image_paths)} JPG files.\")\n",
        "    return image_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q9v6ad568INY"
      },
      "outputs": [],
      "source": [
        "# 3) 바운딩 박스 처리 (IoU, 중복 제거 등)\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    두 바운딩 박스 사이의 IoU(Intersection over Union)를 계산한다.\n",
        "    box1, box2: (x_min, y_min, x_max, y_max) 형태의 좌표 튜플\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = box1\n",
        "    x3, y3, x4, y4 = box2\n",
        "\n",
        "    # 교집합 영역 좌표 계산\n",
        "    inter_x1 = max(x1, x3)\n",
        "    inter_y1 = max(y1, y3)\n",
        "    inter_x2 = min(x2, x4)\n",
        "    inter_y2 = min(y2, y4)\n",
        "\n",
        "    # 교집합 면적\n",
        "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
        "\n",
        "    # 각 바운딩 박스 면적\n",
        "    box1_area = (x2 - x1) * (y2 - y1)\n",
        "    box2_area = (x4 - x3) * (y4 - y3)\n",
        "\n",
        "    # IoU 계산\n",
        "    return inter_area / (box1_area + box2_area - inter_area)\n",
        "\n",
        "def filter_duplicate_boxes(bounding_boxes, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    IoU 기반으로 중복된 바운딩 박스를 제거하는 함수.\n",
        "    두 박스가 iou_threshold 이상 겹치면 더 높은 신뢰도(confidence)만 남긴다.\n",
        "    \"\"\"\n",
        "    filtered_boxes = []\n",
        "    for box in bounding_boxes:\n",
        "        keep = True\n",
        "        for fbox in filtered_boxes:\n",
        "            iou = calculate_iou(\n",
        "                (box[\"x_min\"], box[\"y_min\"], box[\"x_max\"], box[\"y_max\"]),\n",
        "                (fbox[\"x_min\"], fbox[\"y_min\"], fbox[\"x_max\"], fbox[\"y_max\"])\n",
        "            )\n",
        "            if iou > iou_threshold:\n",
        "                # 더 높은 confidence를 가진 박스만 남김\n",
        "                if box[\"confidence\"] > fbox[\"confidence\"]:\n",
        "                    filtered_boxes.remove(fbox)\n",
        "                else:\n",
        "                    keep = False\n",
        "                break\n",
        "        if keep:\n",
        "            filtered_boxes.append(box)\n",
        "    return filtered_boxes\n",
        "\n",
        "def generate_unique_suffix(index):\n",
        "    \"\"\"\n",
        "    주어진 인덱스를 기반으로 영문 소문자(a-z) 중 하나를 반환한다.\n",
        "    인덱스를 26으로 나눈 나머지에 따라 a~z를 할당한다.\n",
        "    \"\"\"\n",
        "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "    return alphabet[index % len(alphabet)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dXalFs-O8KAm"
      },
      "outputs": [],
      "source": [
        "# 4) YOLO 모델 추론 후 바운딩 박스 JSON 저장\n",
        "\n",
        "def process_image(image_path, model, page_number, output_folder=\"output_results\"):\n",
        "    \"\"\"\n",
        "    1) YOLO 모델로 이미지 내 객체(표, 그림 등)를 검출\n",
        "    2) 중복 박스 제거 후 JSON으로 저장\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # 모델 예측 수행 (conf=0.2는 confidence threshold)\n",
        "    det_res = model.predict(image_path, imgsz=1024, conf=0.2, device=\"cpu\")\n",
        "\n",
        "    # 추론 결과를 기반으로 바운딩 박스 리스트 생성\n",
        "    bounding_boxes = []\n",
        "    for i, box in enumerate(det_res[0].boxes):\n",
        "        class_name = model.names[int(box.cls)]  # 클래스 이름(예: table, figure)\n",
        "        class_number = int(box.cls)            # 클래스 번호\n",
        "        unique_suffix = generate_unique_suffix(i)\n",
        "\n",
        "        bounding_boxes.append({\n",
        "            \"class\": class_name,\n",
        "            \"confidence\": float(box.conf),\n",
        "            \"x_min\": float(box.xyxy[0][0]),\n",
        "            \"y_min\": float(box.xyxy[0][1]),\n",
        "            \"x_max\": float(box.xyxy[0][2]),\n",
        "            \"y_max\": float(box.xyxy[0][3]),\n",
        "            \"unique_id\": f\"{page_number}_{class_number}_{unique_suffix}\"  # 페이지번호_클래스번호_고유문자\n",
        "        })\n",
        "\n",
        "    # IoU 기반 중복 제거\n",
        "    filtered_boxes = filter_duplicate_boxes(bounding_boxes, iou_threshold=0.5)\n",
        "\n",
        "    # JSON 파일로 저장\n",
        "    json_output_path = os.path.join(output_folder, f\"page_{page_number}_filtered_boxes.json\")\n",
        "    with open(json_output_path, \"w\") as f:\n",
        "        json.dump(filtered_boxes, f, indent=4)\n",
        "    print(f\"Saved filtered boxes for Page {page_number} to: {json_output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k2HFiuWM8SCS"
      },
      "outputs": [],
      "source": [
        "# 5) YOLO 모델 로드 및 메인 실행 함수\n",
        "\n",
        "def load_yolo_model():\n",
        "    \"\"\"\n",
        "    Hugging Face Hub에서 DocLayout-YOLO 모델 가중치를 다운로드 받아 YOLOv10 모델 객체를 반환한다.\n",
        "    \"\"\"\n",
        "    filepath = hf_hub_download(\n",
        "        repo_id=\"juliozhao/DocLayout-YOLO-DocStructBench\",\n",
        "        filename=\"doclayout_yolo_docstructbench_imgsz1024.pt\"\n",
        "    )\n",
        "    return YOLOv10(filepath)\n",
        "\n",
        "def main(pdf_path, output_folder=\"output_results\"):\n",
        "    \"\"\"\n",
        "    1) YOLO 모델 로딩\n",
        "    2) PDF를 페이지별 이미지를 변환\n",
        "    3) 각 페이지 이미지를 YOLO 추론하여 결과 JSON 저장\n",
        "    \"\"\"\n",
        "    print(\"Loading YOLO model...\")\n",
        "    model = load_yolo_model()\n",
        "\n",
        "    print(\"Converting PDF to images...\")\n",
        "    image_paths = pdf_to_jpg(pdf_path, output_folder=\"images\")\n",
        "\n",
        "    print(\"Processing images...\")\n",
        "    for page_number, image_path in enumerate(image_paths, start=1):\n",
        "        process_image(image_path, model, page_number, output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "7b0a769be4be48e09c7af7594cc10b6f",
            "51cabf9e199b4507a165953a37c5a502",
            "2bd57a1b692f4283b0148d05061d1bb1",
            "cc5193f6c8b940a882914d7e048d4820",
            "1db6efd56af346c489f7c7bc3e2b97c0",
            "d61d51a5b9554a30b072933e6754455b",
            "6fe5180d355b483ab48d5f5270d224a8",
            "f400de1f3d93487e92f3f3e5c06ba1a9",
            "1c3af8d1fe594375ab98d442a13e56a3",
            "44249c49a4fb47ea97a0815b68b3b406",
            "3888ffb8843b4b8684a078d91c124148"
          ]
        },
        "id": "XKHmvz7R8Uc8",
        "outputId": "1cf06897-3087-4947-97be-b7fdc140cce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading YOLO model...\n",
            "Converting PDF to images...\n",
            "Converted PDF to 2 JPG files.\n",
            "Processing images...\n",
            "\n",
            "image 1/1 c:\\Workspace\\images\\page_1.jpg: 1024x736 2 titles, 3 plain texts, 1 abandon, 2 figures, 2 figure_captions, 3102.9ms\n",
            "Speed: 10.9ms preprocess, 3102.9ms inference, 0.0ms postprocess per image at shape (1, 3, 1024, 736)\n",
            "Saved filtered boxes for Page 1 to: output_results\\page_1_filtered_boxes.json\n",
            "\n",
            "image 1/1 c:\\Workspace\\images\\page_2.jpg: 1024x736 1 plain text, 1 abandon, 2 tables, 3062.1ms\n",
            "Speed: 7.6ms preprocess, 3062.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 736)\n",
            "Saved filtered boxes for Page 2 to: output_results\\page_2_filtered_boxes.json\n"
          ]
        }
      ],
      "source": [
        "# 6) PDF → 이미지 + YOLO 바운딩 박스 추출 실행\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"비타민 CV 프로젝트.pdf\"  # 처리할 PDF 경로 (사용자 지정)\n",
        "    main(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJSEwqDY8YCo",
        "outputId": "56184529-bf20-42b4-e51b-578db5b8f8df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table data saved to: output_results\\table_json.json\n",
            "Figure data saved to: output_results\\figure_json.json\n"
          ]
        }
      ],
      "source": [
        "# 7) 클래스별 JSON 파일 통합 (table, figure 등)\n",
        "\n",
        "def combine_json_by_class(directory_path, output_table_file=\"table_json.json\", output_figure_file=\"figure_json.json\"):\n",
        "    \"\"\"\n",
        "    output_results 폴더 내 모든 *_filtered_boxes.json 파일을 확인하여\n",
        "    class=='table' / class=='figure'로 분류한 뒤 각각 table_json.json, figure_json.json에 저장한다.\n",
        "    \"\"\"\n",
        "    table_data = []\n",
        "    figure_data = []\n",
        "\n",
        "    # *_filtered_boxes.json 파일 찾아서 반복\n",
        "    json_files = [f for f in os.listdir(directory_path) if f.endswith(\"_filtered_boxes.json\")]\n",
        "\n",
        "    for json_file in json_files:\n",
        "        json_file_path = os.path.join(directory_path, json_file)\n",
        "        with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # 클래스에 따라 table_data, figure_data에 나누어 담기\n",
        "        for box in data:\n",
        "            if box[\"class\"] == \"table\":\n",
        "                table_data.append(box)\n",
        "            elif box[\"class\"] == \"figure\":\n",
        "                figure_data.append(box)\n",
        "\n",
        "    # 테이블 JSON, 그림 JSON 각각 저장\n",
        "    save_json(os.path.join(directory_path, output_table_file), table_data, \"table\")\n",
        "    save_json(os.path.join(directory_path, output_figure_file), figure_data, \"figure\")\n",
        "\n",
        "def save_json(output_path, data, data_type):\n",
        "    \"\"\"\n",
        "    data를 JSON 파일로 저장. 테이블/그림 등을 구분하기 위해 data_type 사용.\n",
        "    \"\"\"\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "    print(f\"{data_type.capitalize()} data saved to: {output_path}\")\n",
        "\n",
        "# 결합 실행 예시\n",
        "directory_path = \"output_results\"  # YOLO 바운딩 박스 결과 JSON 폴더\n",
        "combine_json_by_class(directory_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZBmYXsK86vE",
        "outputId": "8829892a-092b-4737-a199-29c386d95e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved cropped image to: cropped_images\\figure\\1_3_c.jpg\n",
            "Saved cropped image to: cropped_images\\figure\\1_3_e.jpg\n",
            "Saved cropped image to: cropped_images\\table\\2_5_a.jpg\n",
            "Saved cropped image to: cropped_images\\table\\2_5_c.jpg\n"
          ]
        }
      ],
      "source": [
        "# 8) JSON 바운딩 박스를 바탕으로 이미지 크롭 & 저장\n",
        "\n",
        "def crop_and_save_by_json(image_dir, json_path, output_dir):\n",
        "    \"\"\"\n",
        "    json_path에 정의된 바운딩 박스 좌표를 사용해\n",
        "    image_dir의 원본 이미지를 잘라내어(output_dir에) 저장한다.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # 바운딩 박스 정보 로드\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        bounding_boxes = json.load(f)\n",
        "\n",
        "    # 각 박스별로 이미지를 잘라(crop)서 저장\n",
        "    for box in bounding_boxes:\n",
        "        # unique_id에서 페이지 번호 추출\n",
        "        page_number = int(box[\"unique_id\"].split(\"_\")[0])\n",
        "        image_name = f\"page_{page_number}.jpg\"\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"이미지를 불러올 수 없습니다: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        x_min = int(box[\"x_min\"])\n",
        "        y_min = int(box[\"y_min\"])\n",
        "        x_max = int(box[\"x_max\"])\n",
        "        y_max = int(box[\"y_max\"])\n",
        "\n",
        "        cropped_image = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "        # crop된 이미지를 고유 ID를 파일명 삼아 저장\n",
        "        save_path = os.path.join(output_dir, f\"{box['unique_id']}.jpg\")\n",
        "        cv2.imwrite(save_path, cropped_image)\n",
        "        print(f\"Saved cropped image to: {save_path}\")\n",
        "\n",
        "# 테이블/그림 크롭 실행 예시\n",
        "image_dir = \"images\"               # PDF → JPG 변환된 페이지 이미지 폴더\n",
        "output_dir_base = \"cropped_images\" # 잘라낸 이미지가 저장될 기본 폴더\n",
        "\n",
        "# figure / table 각각 크롭\n",
        "json_files = {\n",
        "    \"figure\": \"output_results/figure_json.json\",\n",
        "    \"table\": \"output_results/table_json.json\"\n",
        "}\n",
        "\n",
        "for category, json_path in json_files.items():\n",
        "    output_dir = os.path.join(output_dir_base, category)\n",
        "    crop_and_save_by_json(image_dir, json_path, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j0jKvRv9A9c",
        "outputId": "108b0960-79ff-4977-c587-5ee39a4526bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Images:   0%|          | 0/2 [00:00<?, ?it/s]Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 OpenCV CUDA 사용 여부: False\n",
            "🔥 EasyOCR GPU 사용 여부: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Images:  50%|█████     | 1/2 [00:23<00:23, 23.15s/it]Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 OpenCV CUDA 사용 여부: False\n",
            "🔥 EasyOCR GPU 사용 여부: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Images: 100%|██████████| 2/2 [00:34<00:00, 17.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Extracted text saved to: outputs\\result_table.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
            "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
            "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
            "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import easyocr\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "class ImageProcessor:\n",
        "    \"\"\"\n",
        "    전처리를 위한 클래스.\n",
        "    (그레이스케일, 블러, 이진화, 모폴로지 연산 등)\n",
        "    \"\"\"\n",
        "    def __init__(self, image):\n",
        "        self.image = image\n",
        "        if self.image is None:\n",
        "            raise ValueError(\"Could not load image\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        \"\"\"\n",
        "        GPU 가속을 활용한 이미지 전처리 (그레이스케일, 블러, 이진화)\n",
        "        \"\"\"\n",
        "        if len(self.image.shape) == 3:\n",
        "            self.gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            self.gray = self.image\n",
        "\n",
        "        # OpenCV CUDA 사용 가능 여부 확인\n",
        "        self.use_cuda = cv2.cuda.getCudaEnabledDeviceCount() > 0\n",
        "        print(f\"🔹 OpenCV CUDA 사용 여부: {self.use_cuda}\")\n",
        "\n",
        "        if self.use_cuda:\n",
        "            gpu_img = cv2.cuda_GpuMat()\n",
        "            gpu_img.upload(self.gray)\n",
        "            gpu_blurred = cv2.cuda.GaussianBlur(gpu_img, (5, 5), 0)\n",
        "            self.blurred = gpu_blurred.download()\n",
        "        else:\n",
        "            self.blurred = cv2.GaussianBlur(self.gray, (5, 5), 0)\n",
        "\n",
        "        _, self.binary = cv2.threshold(self.blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        return self.binary\n",
        "\n",
        "    def apply_morphology(self):\n",
        "        \"\"\"\n",
        "        모폴로지 연산을 통해 표의 선(가로/세로 선 등)을 추출하는 예시 (선택적)\n",
        "        \"\"\"\n",
        "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
        "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))\n",
        "\n",
        "        self.horizontal_lines = cv2.morphologyEx(self.binary, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
        "        self.vertical_lines = cv2.morphologyEx(self.binary, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
        "        self.morph_result = cv2.bitwise_or(self.horizontal_lines, self.vertical_lines)\n",
        "        return self.morph_result\n",
        "\n",
        "class TextExtractor:\n",
        "    \"\"\"\n",
        "    EasyOCR 기반으로 이미지를 읽어 텍스트를 추출하는 클래스.\n",
        "    \"\"\"\n",
        "    def __init__(self, language=['ko']):\n",
        "        self.use_gpu = torch.cuda.is_available()\n",
        "        print(f\"EasyOCR GPU 사용 여부: {self.use_gpu}\")\n",
        "\n",
        "        self.reader = easyocr.Reader(language, gpu=self.use_gpu)\n",
        "\n",
        "    def extract_text(self, image):\n",
        "        \"\"\"이미지로부터 텍스트를 추출하여 리턴\"\"\"\n",
        "        text_result = self.reader.readtext(image, detail=0)\n",
        "        return \"\\n\".join(text_result).strip()\n",
        "\n",
        "def process_images_in_directory(input_dir, output_dir):\n",
        "    \"\"\"\n",
        "    input_dir 내의 모든 이미지에 대해 전처리 + OCR 수행 후,\n",
        "    추출된 텍스트를 JSON으로 저장한다.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(input_dir):\n",
        "        raise ValueError(f\"Input directory does not exist: {input_dir}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 폴더 내 모든 이미지 파일 반복 처리\n",
        "    for file_name in tqdm(os.listdir(input_dir), desc=\"Processing Images\"):\n",
        "        if file_name.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")):\n",
        "            image_path = os.path.join(input_dir, file_name)\n",
        "\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                print(f\"Failed to read image: {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # 이미지 전처리 & OCR\n",
        "            try:\n",
        "                processor = ImageProcessor(image)\n",
        "                binary = processor.preprocess()\n",
        "                processor.apply_morphology()\n",
        "\n",
        "                extractor = TextExtractor()\n",
        "                extracted_text = extractor.extract_text(image)\n",
        "\n",
        "                results.append({\n",
        "                    \"file_name\": file_name,\n",
        "                    \"extracted_text\": extracted_text\n",
        "                })\n",
        "\n",
        "                # GPU 메모리 캐시 정리\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "    # 최종 OCR 결과 JSON으로 저장\n",
        "    save_results_as_json(results, output_dir)\n",
        "\n",
        "def save_results_as_json(results, output_dir):\n",
        "    \"\"\"\n",
        "    OCR 추출 결과를 JSON 파일로 저장.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    results_json_path = os.path.join(output_dir, \"result_table.json\")\n",
        "    with open(results_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
        "    print(f\" Extracted text saved to: {results_json_path}\")\n",
        "\n",
        "# 표 이미지를 OCR 실행 예시\n",
        "input_dir = \"cropped_images/table\"\n",
        "output_dir = \"outputs\"\n",
        "process_images_in_directory(input_dir, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH5QltkI9Exu",
        "outputId": "15862db3-8565-4082-d0a1-ad40af96896d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: CPU\n",
            "[Start] 2025-02-02 13:12:34.412815+09:00 / Total images: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Images: 100%|██████████| 2/2 [03:03<00:00, 91.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[End] 2025-02-02 13:15:37.868168+09:00 / Processed: 2\n",
            "[Done] JSON results saved to: /content/outputs/result_figure.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 10) 그림(차트) 이미지(Pix2Struct) 처리\n",
        "#  - brainventures/ko-deplot 모델 사용\n",
        "\n",
        "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from PIL import Image\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "MAX_PATCHES = 512  # Pix2Struct에서 사용할 max_patches 파라미터\n",
        "\n",
        "class ImageToDataTable:\n",
        "    \"\"\"\n",
        "    Hugging Face Hub에 있는 'brainventures/deplot_kr' 모델을 사용하여,\n",
        "    그래프/차트 이미지를 구조화된 텍스트(데이터 테이블 등)로 변환하는 클래스.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_id: str = \"brainventures/deplot_kr\", output_dir: str = \"outputs\", device: str = None):\n",
        "        # 디바이스 설정 (GPU가 있으면 cuda, 없으면 cpu)\n",
        "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.output_dir = output_dir\n",
        "        self.model_id = model_id\n",
        "\n",
        "        # GPU 사용 여부 확인\n",
        "        print(f\"Using device: {self.device.upper()}\")\n",
        "\n",
        "        # 모델 로드: 한국어 DePlot (brainventures/deplot_kr)\n",
        "        self.processor = Pix2StructProcessor.from_pretrained(model_id)\n",
        "        self.model = Pix2StructForConditionalGeneration.from_pretrained(model_id)\n",
        "\n",
        "        # 모델을 지정한 디바이스로 이동\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # 결과 저장 디렉토리\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "    def process_image(self, image_path: str, prompt: str = None):\n",
        "        \"\"\"\n",
        "        단일 이미지를 Pix2Struct로 추론하여 결과 텍스트를 반환.\n",
        "        prompt: 모델에게 '데이터 테이블을 생성하라'는 지시문 등. (기본 영문 프롬프트 예시)\n",
        "        \"\"\"\n",
        "        if prompt is None:\n",
        "            prompt = \"Generate underlying data table of the figure below:\"\n",
        "\n",
        "        data_id = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "        # 이미지 로드\n",
        "        try:\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"[Error] Failed to open image {data_id}: {e}\")\n",
        "            return None, None\n",
        "\n",
        "        # 모델 입력 구성\n",
        "        inputs = self.processor(images=image, text=prompt, return_tensors=\"pt\", max_patches=MAX_PATCHES)\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "        # 모델 추론\n",
        "        with torch.no_grad():\n",
        "            generated_ids = self.model.generate(**inputs, max_new_tokens=512)\n",
        "\n",
        "        # 결과 텍스트 디코딩\n",
        "        generated_text = self.processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        # prompt 문장을 제거한 결과 반환\n",
        "        clean_text = generated_text[len(prompt):].strip()\n",
        "        return data_id, clean_text\n",
        "\n",
        "    def process_images(self, image_paths, prompt: str = None):\n",
        "        \"\"\"\n",
        "        여러 이미지를 한 번에 처리하고, JSON으로 결과를 저장한다.\n",
        "        \"\"\"\n",
        "        log_path = os.path.join(self.output_dir, \"evaluation_log.txt\")\n",
        "        json_data = []\n",
        "\n",
        "        # 시작 시간 로그\n",
        "        with open(log_path, \"a\", encoding='utf-8') as log_file:\n",
        "            current_time = datetime.now(timezone('Asia/Seoul'))\n",
        "            print(f\"[Start] {current_time} / Total images: {len(image_paths)}\")\n",
        "            log_file.write(f\"Start: {current_time} / Data: {len(image_paths)}\\n\")\n",
        "\n",
        "            for image_path in tqdm(image_paths, desc=\"Processing Images\"):\n",
        "                data_id, clean_text = self.process_image(image_path, prompt)\n",
        "                if clean_text:\n",
        "                    json_data.append({\n",
        "                        \"data_id\": data_id,\n",
        "                        \"generated_text\": clean_text  # prompt 제거된 순수 생성문 저장\n",
        "                    })\n",
        "\n",
        "            current_time = datetime.now(timezone('Asia/Seoul'))\n",
        "            print(f\"[End] {current_time} / Processed: {len(json_data)}\")\n",
        "            log_file.write(f\"End: {current_time} / Data: {len(json_data)}\\n\")\n",
        "\n",
        "        # 결과 저장\n",
        "        self._save_results(json_data)\n",
        "\n",
        "    def _save_results(self, json_data):\n",
        "        \"\"\"\n",
        "        결과를 result_figure.json으로 저장.\n",
        "        \"\"\"\n",
        "        json_output_path = os.path.join(self.output_dir, \"result_figure.json\")\n",
        "        with open(json_output_path, \"w\", encoding='utf-8') as jf:\n",
        "            json.dump(json_data, jf, ensure_ascii=False, indent=4)\n",
        "        print(f\"[Done] JSON results saved to: {json_output_path}\")\n",
        "\n",
        "\n",
        "def get_image_paths(data_path: str):\n",
        "    \"\"\"\n",
        "    지정된 폴더에서 지원되는 확장자(.jpg, .png 등) 파일들의 경로를 수집해 리스트로 반환\n",
        "    \"\"\"\n",
        "    supported_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif')\n",
        "    return [\n",
        "        os.path.join(data_path, fname)\n",
        "        for fname in os.listdir(data_path)\n",
        "        if fname.lower().endswith(supported_extensions)\n",
        "    ]\n",
        "\n",
        "# ------------ 실행 예시 -------------\n",
        "DEFAULT_DATA_PATH = \"/content/cropped_images/figure\"  # 그림(차트) 이미지가 들어있는 폴더\n",
        "DEFAULT_OUTPUT_DIR = \"/content/outputs\"               # 결과(JSON) 저장 폴더\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) figure 폴더 내의 이미지 경로 수집\n",
        "    image_paths = get_image_paths(DEFAULT_DATA_PATH)\n",
        "    if not image_paths:\n",
        "        raise ValueError(f\"No supported image files found in {DEFAULT_DATA_PATH}\")\n",
        "\n",
        "    # 2) brainventures/deplot_kr 모델로 초기화\n",
        "    image_to_table = ImageToDataTable(\n",
        "        model_id=\"brainventures/deplot_kr\",\n",
        "        output_dir=DEFAULT_OUTPUT_DIR\n",
        "    )\n",
        "\n",
        "    # 3) 일괄 처리 (프롬프트는 원하는 문구로 교체 가능)\n",
        "    image_to_table.process_images(\n",
        "        image_paths=image_paths,\n",
        "        prompt=\"다음 차트의 데이터 표를 한국어로 상세히 출력해줘:\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDKlrakAFvCh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c3af8d1fe594375ab98d442a13e56a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1db6efd56af346c489f7c7bc3e2b97c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd57a1b692f4283b0148d05061d1bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f400de1f3d93487e92f3f3e5c06ba1a9",
            "max": 40709302,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c3af8d1fe594375ab98d442a13e56a3",
            "value": 40709302
          }
        },
        "3888ffb8843b4b8684a078d91c124148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44249c49a4fb47ea97a0815b68b3b406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51cabf9e199b4507a165953a37c5a502": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d61d51a5b9554a30b072933e6754455b",
            "placeholder": "​",
            "style": "IPY_MODEL_6fe5180d355b483ab48d5f5270d224a8",
            "value": "(…)clayout_yolo_docstructbench_imgsz1024.pt: 100%"
          }
        },
        "6fe5180d355b483ab48d5f5270d224a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b0a769be4be48e09c7af7594cc10b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51cabf9e199b4507a165953a37c5a502",
              "IPY_MODEL_2bd57a1b692f4283b0148d05061d1bb1",
              "IPY_MODEL_cc5193f6c8b940a882914d7e048d4820"
            ],
            "layout": "IPY_MODEL_1db6efd56af346c489f7c7bc3e2b97c0"
          }
        },
        "cc5193f6c8b940a882914d7e048d4820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44249c49a4fb47ea97a0815b68b3b406",
            "placeholder": "​",
            "style": "IPY_MODEL_3888ffb8843b4b8684a078d91c124148",
            "value": " 40.7M/40.7M [00:01&lt;00:00, 39.9MB/s]"
          }
        },
        "d61d51a5b9554a30b072933e6754455b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f400de1f3d93487e92f3f3e5c06ba1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
